{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport zipfile\nimport cv2\nfrom skimage import io\n\nimport tensorflow as tf\nfrom tensorflow.python.keras import Sequential\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nimport tensorflow.keras.backend as K\n\nimport random\nimport glob\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom IPython.display import display\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:11.022044Z","iopub.execute_input":"2022-07-07T11:36:11.023703Z","iopub.status.idle":"2022-07-07T11:36:12.047797Z","shell.execute_reply.started":"2022-07-07T11:36:11.023661Z","shell.execute_reply":"2022-07-07T11:36:12.046832Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"WHAT IS THE PURPOSE OF THIS NOTEBOOK?\n\n\nThe notebook is divided into two sections:\n\n1. Image Categorization (i.e whether the Image has tumour or not)\n\nCONTENTS:\n\n\n\nLIBRARIES AND DATASETS IMPORT\n\nTHE VISUALIZATION OF DATA\n\nGENERATING TRAINING, VALIDATION, AND TEST DATASETS\n\nTHE MODEL'S TRAINING\n\nEVALUATION\n\n2. Image Segmentation (i.e., if the image has a tumour, forecast the region where the tumour is located; simply, we need to map all of the pixel values to a label of 0 or 1, and that's all there is to it)\n\nCONTENTS:\n\n\n\nMASKED ELEMENTS DATASET CREATION\n\nCREATING A PERSONALIZED DATA GENERATOR\n\nFORMING A RESNET BLOCK\n\nMODEL OF TRAINING SEGMENTATION\n\nEVALUATION OF SEGMENTATION MODELS\n\nSEGMENTATION MODEL PREDICTION\n\nA personal note:\nThe notebook will be almost identical to the one mentioned above, but I wanted to practise the problems of Image Segmentation and Classification, so I thought of making a notebook, (sought of tutorial, so that I can revisit this notebook, as and when required), all credit goes to the author of Brain MRI Detection | Segmentation | ResUNet, thanks and best wishes","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/lgg-mri-segmentation/kaggle_3m/data.csv')\ndata.info()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:12.049438Z","iopub.execute_input":"2022-07-07T11:36:12.049774Z","iopub.status.idle":"2022-07-07T11:36:12.085495Z","shell.execute_reply.started":"2022-07-07T11:36:12.049739Z","shell.execute_reply":"2022-07-07T11:36:12.084416Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data.head(10)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:12.088658Z","iopub.execute_input":"2022-07-07T11:36:12.089045Z","iopub.status.idle":"2022-07-07T11:36:12.129324Z","shell.execute_reply.started":"2022-07-07T11:36:12.089007Z","shell.execute_reply":"2022-07-07T11:36:12.128348Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_map = []\nfor sub_dir_path in glob.glob(\"/kaggle/input/lgg-mri-segmentation/kaggle_3m/\"+\"*\"):\n    #if os.path.isdir(sub_path_dir):\n    try:\n        dir_name = sub_dir_path.split('/')[-1]\n        for filename in os.listdir(sub_dir_path):\n            image_path = sub_dir_path + '/' + filename\n            data_map.extend([dir_name, image_path])\n    except Exception as e:\n        print(e)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:12.130970Z","iopub.execute_input":"2022-07-07T11:36:12.131633Z","iopub.status.idle":"2022-07-07T11:36:12.184907Z","shell.execute_reply.started":"2022-07-07T11:36:12.131596Z","shell.execute_reply":"2022-07-07T11:36:12.183923Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\"patient_id\" : data_map[::2],\n                   \"path\" : data_map[1::2]})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:12.186582Z","iopub.execute_input":"2022-07-07T11:36:12.187228Z","iopub.status.idle":"2022-07-07T11:36:12.200441Z","shell.execute_reply.started":"2022-07-07T11:36:12.187191Z","shell.execute_reply":"2022-07-07T11:36:12.199382Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_imgs = df[~df['path'].str.contains(\"mask\")]\ndf_masks = df[df['path'].str.contains(\"mask\")]\n\n# File path line length images for later sorting\nBASE_LEN = 89 # len(/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_ <-!!!43.tif)\nEND_IMG_LEN = 4 # len(/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->.tif)\nEND_MASK_LEN = 9 # (/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->_mask.tif)\n\n# Data sorting\nimgs = sorted(df_imgs[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_IMG_LEN]))\nmasks = sorted(df_masks[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_MASK_LEN]))\n\n# Sorting check\nidx = random.randint(0, len(imgs)-1)\nprint(\"Path to the Image:\", imgs[idx], \"\\nPath to the Mask:\", masks[idx])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:12.202156Z","iopub.execute_input":"2022-07-07T11:36:12.202888Z","iopub.status.idle":"2022-07-07T11:36:12.229183Z","shell.execute_reply.started":"2022-07-07T11:36:12.202851Z","shell.execute_reply":"2022-07-07T11:36:12.228071Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Final dataframe\nbrain_df = pd.DataFrame({\"patient_id\": df_imgs.patient_id.values,\n                         \"image_path\": imgs,\n                         \"mask_path\": masks\n                        })\ndef pos_neg_diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    if value > 0 : \n        return 1\n    else:\n        return 0\n    \nbrain_df['mask'] = brain_df['mask_path'].apply(lambda x: pos_neg_diagnosis(x))\nbrain_df","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:12.231099Z","iopub.execute_input":"2022-07-07T11:36:12.231811Z","iopub.status.idle":"2022-07-07T11:36:36.815330Z","shell.execute_reply.started":"2022-07-07T11:36:12.231757Z","shell.execute_reply":"2022-07-07T11:36:36.814400Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"brain_df['mask'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:36.816600Z","iopub.execute_input":"2022-07-07T11:36:36.817685Z","iopub.status.idle":"2022-07-07T11:36:36.826307Z","shell.execute_reply.started":"2022-07-07T11:36:36.817644Z","shell.execute_reply":"2022-07-07T11:36:36.825293Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go  # using plotly to create interactive plots\n\nfig = go.Figure([go.Bar(x=brain_df['mask'].value_counts().index, \n                        y=brain_df['mask'].value_counts(), \n                        width=[.4, .4]\n                       )\n                ])\nfig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n                  marker_line_width=4, opacity=0.4\n                 )\nfig.update_layout(title_text=\"Mask Count Plot\",\n                  width=700,\n                  height=550,\n                  yaxis=dict(\n                             title_text=\"Count\",\n                             tickmode=\"array\",\n                             titlefont=dict(size=20)\n                           )\n                 )\nfig.update_yaxes(automargin=True)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:36.829992Z","iopub.execute_input":"2022-07-07T11:36:36.830249Z","iopub.status.idle":"2022-07-07T11:36:36.984827Z","shell.execute_reply.started":"2022-07-07T11:36:36.830226Z","shell.execute_reply":"2022-07-07T11:36:36.983778Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"1 indicates the number of people having tumor and it is very less compared to the not affected.","metadata":{}},{"cell_type":"code","source":"# Printing the Tumor Image\nfor i in range(len(brain_df)):\n    if cv2.imread(brain_df['mask_path'][i]).max()>0:\n        break\n\nplt.figure(figsize=(12,8))\nplt.subplot(121)\nplt.imshow(cv2.imread(brain_df['mask_path'][i]));\nplt.title('Tumor Location')\nplt.axis('off')\nplt.subplot(122)\nplt.imshow(cv2.imread(brain_df['image_path'][i]));\nplt.title(\"Brain MRI Image\")\nplt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:36.986367Z","iopub.execute_input":"2022-07-07T11:36:36.986954Z","iopub.status.idle":"2022-07-07T11:36:37.864564Z","shell.execute_reply.started":"2022-07-07T11:36:36.986917Z","shell.execute_reply":"2022-07-07T11:36:37.863485Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"cv2.imread(brain_df['mask_path'][i]).max(),cv2.imread(brain_df['mask_path'][i]).min()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:37.866064Z","iopub.execute_input":"2022-07-07T11:36:37.866660Z","iopub.status.idle":"2022-07-07T11:36:37.878110Z","shell.execute_reply.started":"2022-07-07T11:36:37.866624Z","shell.execute_reply":"2022-07-07T11:36:37.877025Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Plot Random Images","metadata":{}},{"cell_type":"code","source":"fig,axs = plt.subplots(6,2,figsize=(16,26))\ncount = 0\nfor x in range(6):\n    i = random.randint(0,len(brain_df))\n    axs[count][0].title.set_text(\"Brain MRI\")\n    axs[count][0].imshow(cv2.imread(brain_df['image_path'][i]))\n    axs[count][1].title.set_text(\"Mask - \"+str(brain_df['mask'][i]))\n    axs[count][1].imshow(cv2.imread(brain_df['mask_path'][i]))\n    axs[count][0].axis('off')\n    axs[count][1].axis('off')\n    count+=1\nfig.tight_layout()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:37.879680Z","iopub.execute_input":"2022-07-07T11:36:37.880108Z","iopub.status.idle":"2022-07-07T11:36:38.888080Z","shell.execute_reply.started":"2022-07-07T11:36:37.880073Z","shell.execute_reply":"2022-07-07T11:36:38.885503Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Perform Masking","metadata":{}},{"cell_type":"code","source":"count = 0\ni = 0\nfig,axs= plt.subplots(12,3,figsize=(20,50))\nfor mask in brain_df['mask']:\n    if(mask==1):\n        img = io.imread(brain_df['image_path'][i])\n        axs[count][0].title.set_text(\"Brain MRI\")\n        axs[count][0].imshow(img)\n        \n        mask = io.imread(brain_df['mask_path'][i])\n        axs[count][1].title.set_text('Mask')\n        axs[count][1].imshow(mask,cmap ='gray')\n        img[mask==255]=(0,255,150)\n        axs[count][2].title.set_text('MRI with Mask')\n        axs[count][2].imshow(img)\n        axs[count][0].axis('off')\n        axs[count][1].axis('off')\n        axs[count][2].axis('off')\n        count+=1\n    i+=1\n    if(count==12):\n        break\nfig.tight_layout()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:38.889490Z","iopub.execute_input":"2022-07-07T11:36:38.890512Z","iopub.status.idle":"2022-07-07T11:36:41.852054Z","shell.execute_reply.started":"2022-07-07T11:36:38.890470Z","shell.execute_reply":"2022-07-07T11:36:41.851080Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Create Train, Test, Val dataset","metadata":{}},{"cell_type":"code","source":"brain_df_train = brain_df.drop(columns=['patient_id'])\nbrain_df_train['mask'] = brain_df_train['mask'].apply(lambda x: str(x))\nbrain_df_train.info()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:41.853599Z","iopub.execute_input":"2022-07-07T11:36:41.854624Z","iopub.status.idle":"2022-07-07T11:36:41.880171Z","shell.execute_reply.started":"2022-07-07T11:36:41.854586Z","shell.execute_reply":"2022-07-07T11:36:41.879168Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain,test = train_test_split(brain_df_train,test_size=0.15) # Splitting the data\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:41.881773Z","iopub.execute_input":"2022-07-07T11:36:41.882785Z","iopub.status.idle":"2022-07-07T11:36:41.942363Z","shell.execute_reply.started":"2022-07-07T11:36:41.882750Z","shell.execute_reply":"2022-07-07T11:36:41.941047Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from keras_preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rescale=1./255,validation_split=0.1)\n# Creating dataset\ntrain_generator = datagen.flow_from_dataframe(train,directory = './',\n                x_col = 'image_path',y_col='mask',subset='training',class_mode='categorical',\n                                             batch_size=16,shuffle=True,target_size=(256,256))\nvalid_generator = datagen.flow_from_dataframe(train,directory='./',\n                                x_col = 'image_path',y_col = 'mask',\n                                             subset='validation',class_mode='categorical',batch_size=16,shuffle=True,target_size=(256,256))\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_dataframe(test,directory='./',x_col='image_path',y_col = 'mask',class_mode='categorical',batch_size=16,shuffle=False,target_size=(256,256))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:41.944316Z","iopub.execute_input":"2022-07-07T11:36:41.944722Z","iopub.status.idle":"2022-07-07T11:36:43.471238Z","shell.execute_reply.started":"2022-07-07T11:36:41.944685Z","shell.execute_reply":"2022-07-07T11:36:43.470210Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Create and Train Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:36:43.474163Z","iopub.execute_input":"2022-07-07T11:36:43.474527Z","iopub.status.idle":"2022-07-07T11:36:43.481338Z","shell.execute_reply.started":"2022-07-07T11:36:43.474498Z","shell.execute_reply":"2022-07-07T11:36:43.480334Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"clf_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(256,256,3)))\nclf_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:37:59.442012Z","iopub.execute_input":"2022-07-07T11:37:59.442934Z","iopub.status.idle":"2022-07-07T11:38:01.052311Z","shell.execute_reply.started":"2022-07-07T11:37:59.442898Z","shell.execute_reply":"2022-07-07T11:38:01.051364Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"for layer in clf_model.layers:\n    layers.trainable = False\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:38:12.898538Z","iopub.execute_input":"2022-07-07T11:38:12.899146Z","iopub.status.idle":"2022-07-07T11:38:12.904230Z","shell.execute_reply.started":"2022-07-07T11:38:12.899111Z","shell.execute_reply":"2022-07-07T11:38:12.903204Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"head = clf_model.output\nhead = AveragePooling2D(pool_size=(4,4))(head)\nhead = Flatten(name='Flatten')(head)\nhead = Dense(256, activation='relu')(head)\nhead = Dropout(0.3)(head)\nhead = Dense(256, activation='relu')(head)\nhead = Dropout(0.3)(head)\nhead = Dense(2, activation='softmax')(head)\n\nmodel = Model(clf_model.input, head)\nmodel.compile(loss = 'categorical_crossentropy', \n              optimizer='adam', \n              metrics= [\"accuracy\"]\n             )\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:38:21.835403Z","iopub.execute_input":"2022-07-07T11:38:21.836222Z","iopub.status.idle":"2022-07-07T11:38:21.917562Z","shell.execute_reply.started":"2022-07-07T11:38:21.836187Z","shell.execute_reply":"2022-07-07T11:38:21.916606Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"early_stopping= EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=15) # Early stopping, if our validation loss does not improve\ncheck_pointer = ModelCheckpoint(filepath = 'clf-resnet-weights.hdf5',verbose=1,save_best_only=True) # Save only the best model, by monitoring the validation loss\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',mode='min',verbose=1,patience=10,min_delta = 0.0001,factor=0.2) # Reduce the Learning Rate, by monitori\ncallbacks = [check_pointer,early_stopping,reduce_lr]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:38:54.151628Z","iopub.execute_input":"2022-07-07T11:38:54.152193Z","iopub.status.idle":"2022-07-07T11:38:54.161824Z","shell.execute_reply.started":"2022-07-07T11:38:54.152150Z","shell.execute_reply":"2022-07-07T11:38:54.160787Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"h = model.fit(train_generator,steps_per_epoch = train_generator.n//train_generator.batch_size,\n                        epochs=100,validation_data=valid_generator,validation_steps = valid_generator.n//valid_generator.batch_size,\n                             callbacks = [check_pointer,early_stopping])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T11:52:24.769994Z","iopub.execute_input":"2022-07-07T11:52:24.770365Z","iopub.status.idle":"2022-07-07T12:01:43.966195Z","shell.execute_reply.started":"2022-07-07T11:52:24.770334Z","shell.execute_reply":"2022-07-07T12:01:43.965132Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Saving the Model architecture in json file\nmodel_json = model.to_json()\nwith open('clf-resnet-model.json','w') as json_file:\n    json_file.write(model_json)\nmodel.save('clf-brain.hdf5')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:04:20.635069Z","iopub.execute_input":"2022-07-07T12:04:20.635450Z","iopub.status.idle":"2022-07-07T12:04:21.813413Z","shell.execute_reply.started":"2022-07-07T12:04:20.635404Z","shell.execute_reply":"2022-07-07T12:04:21.812479Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"h.history.keys()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:04:30.274593Z","iopub.execute_input":"2022-07-07T12:04:30.275016Z","iopub.status.idle":"2022-07-07T12:04:30.287404Z","shell.execute_reply.started":"2022-07-07T12:04:30.274979Z","shell.execute_reply":"2022-07-07T12:04:30.286394Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(121)\nplt.plot(h.history['loss'])\nplt.plot(h.history['val_loss'])\nplt.title(\"Classification Model LOSS\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend(['train','val'])\n\nplt.subplot(122)\nplt.plot(h.history['accuracy'])\nplt.plot(h.history['val_accuracy'])\nplt.title(\"Classification Model Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend(['train','val'])\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:04:46.764226Z","iopub.execute_input":"2022-07-07T12:04:46.764739Z","iopub.status.idle":"2022-07-07T12:04:47.111286Z","shell.execute_reply.started":"2022-07-07T12:04:46.764695Z","shell.execute_reply":"2022-07-07T12:04:47.110386Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"_,acc = model.evaluate(test_generator)\nprint(\"Test Accuracy :  {} %\".format(acc*100))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:05:14.166846Z","iopub.execute_input":"2022-07-07T12:05:14.167197Z","iopub.status.idle":"2022-07-07T12:05:20.288886Z","shell.execute_reply.started":"2022-07-07T12:05:14.167169Z","shell.execute_reply":"2022-07-07T12:05:20.287804Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(test_generator)\npred = np.argmax(prediction,axis=1)\noriginal = np.asarray(test['mask']).astype('int')\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\naccuracy = accuracy_score(original,pred)\nprint(accuracy)\n\ncm = confusion_matrix(original,pred)\nreport = classification_report(original,pred,labels=[0,1])\nprint(report)\nplt.figure(figsize=(5,5))\nsns.heatmap(cm,annot=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:05:31.861070Z","iopub.execute_input":"2022-07-07T12:05:31.861436Z","iopub.status.idle":"2022-07-07T12:05:36.432658Z","shell.execute_reply.started":"2022-07-07T12:05:31.861390Z","shell.execute_reply":"2022-07-07T12:05:36.431708Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Building a Segmentation Model to Localize Tumour\n\n\n","metadata":{}},{"cell_type":"markdown","source":"Create dataset of masked elements","metadata":{}},{"cell_type":"code","source":"brain_df_mask = brain_df[brain_df['mask']==1]\nbrain_df_mask.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:06:33.743840Z","iopub.execute_input":"2022-07-07T12:06:33.744201Z","iopub.status.idle":"2022-07-07T12:06:33.754138Z","shell.execute_reply.started":"2022-07-07T12:06:33.744170Z","shell.execute_reply":"2022-07-07T12:06:33.753060Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"X_train,X_val = train_test_split(brain_df_mask,test_size=0.15)\nX_test,X_val = train_test_split(X_val,test_size=0.5)\n\nprint(\"Train Size is {}, validation size is {} & test size is {}\".format(len(X_train),len(X_val),len(X_test)))\n      \ntrain_ids = list(X_train.image_path)\ntrain_mask = list(X_train.mask_path)\n      \nval_ids = list(X_val.image_path)\nval_mask = list(X_val.mask_path)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:06:47.077242Z","iopub.execute_input":"2022-07-07T12:06:47.077618Z","iopub.status.idle":"2022-07-07T12:06:47.090081Z","shell.execute_reply.started":"2022-07-07T12:06:47.077585Z","shell.execute_reply":"2022-07-07T12:06:47.089016Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n  def __init__(self, ids , mask, image_dir = './', batch_size = 16, img_h = 256, img_w = 256, shuffle = True):\n\n    self.ids = ids\n    self.mask = mask\n    self.image_dir = image_dir\n    self.batch_size = batch_size\n    self.img_h = img_h\n    self.img_w = img_w\n    self.shuffle = shuffle\n    self.on_epoch_end()\n\n  def __len__(self):\n    'Get the number of batches per epoch'\n\n    return int(np.floor(len(self.ids)) / self.batch_size)\n\n  def __getitem__(self, index):\n    'Generate a batch of data'\n\n    #generate index of batch_size length\n    indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]\n\n    #get the ImageId corresponding to the indexes created above based on batch size\n    list_ids = [self.ids[i] for i in indexes]\n\n    #get the MaskId corresponding to the indexes created above based on batch size\n    list_mask = [self.mask[i] for i in indexes]\n\n\n    #generate data for the X(features) and y(label)\n    X, y = self.__data_generation(list_ids, list_mask)\n\n    #returning the data\n    return X, y\n  def on_epoch_end(self):\n\n    #get the ImageId corresponding to the indexes created above based on batch size\n    self.indexes = np.arange(len(self.ids))\n\n    #if shuffle is true, shuffle the indices\n    if self.shuffle:\n      np.random.shuffle(self.indexes)\n\n  def __data_generation(self, list_ids, list_mask):\n    'generate the data corresponding the indexes in a given batch of images'\n\n    # create empty arrays of shape (batch_size,height,width,depth) \n    #Depth is 3 for input and depth is taken as 1 for output becasue mask consist only of 1 channel.\n    X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n    y = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n\n    #iterate through the dataframe rows, whose size is equal to the batch_size\n    for i in range(len(list_ids)):\n      #path of the image\n      img_path = str(list_ids[i])\n      \n      #mask path\n      mask_path = str(list_mask[i])\n      \n      #reading the original image and the corresponding mask image\n      img = io.imread(img_path)\n      mask = io.imread(mask_path)\n\n      #resizing and coverting them to array of type float64\n      img = cv2.resize(img,(self.img_h,self.img_w))\n      img = np.array(img, dtype = np.float64)\n      \n      mask = cv2.resize(mask,(self.img_h,self.img_w))\n      mask = np.array(mask, dtype = np.float64)\n\n      #standardising \n      img -= img.mean()\n      img /= img.std()\n      \n      mask -= mask.mean()\n      mask /= mask.std()\n      \n      #Adding image to the empty array\n      X[i,] = img\n      \n      #expanding the dimnesion of the image from (256,256) to (256,256,1)\n      y[i,] = np.expand_dims(mask, axis = 2)\n    \n    #normalizing y\n    y = (y > 0).astype(int)\n\n    return X, y\n\ntrain_data = DataGenerator(train_ids, train_mask)\nval_data = DataGenerator(val_ids, val_mask)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:07:20.966525Z","iopub.execute_input":"2022-07-07T12:07:20.966954Z","iopub.status.idle":"2022-07-07T12:07:20.985908Z","shell.execute_reply.started":"2022-07-07T12:07:20.966920Z","shell.execute_reply":"2022-07-07T12:07:20.984764Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def resblock(X,f):\n    X_copy = X\n    X  =Conv2D(f,kernel_size=(1,1),kernel_initializer='he_normal')(X)\n    X = BatchNormalization()(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(f,kernel_size=(3,3),padding='same',kernel_initializer='he_normal')(X)\n    X = BatchNormalization()(X)\n    \n    X_copy = Conv2D(f,kernel_size=(1,1),kernel_initializer='he_normal')(X_copy)\n    X_copy = BatchNormalization()(X_copy)\n    \n    X = Add()([X,X_copy])\n    X =Activation('relu')(X)\n    \n    return X\n\ndef upsample_concat(x,skip):\n    X = UpSampling2D((2,2))(x)\n    merge = Concatenate()([X,skip])\n    return merge","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:08:35.181596Z","iopub.execute_input":"2022-07-07T12:08:35.182052Z","iopub.status.idle":"2022-07-07T12:08:35.197924Z","shell.execute_reply.started":"2022-07-07T12:08:35.182012Z","shell.execute_reply":"2022-07-07T12:08:35.196813Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"input_shape = (256,256,3)\nX_input = Input(input_shape)\n\n# Stage 1\nconv_1 = Conv2D(16,3,activation='relu',padding='same',kernel_initializer='he_normal')(X_input)\nconv_1 =BatchNormalization()(conv_1)\nconv_1 = Conv2D(16,3,activation='relu',padding='same',kernel_initializer='he_normal')(conv_1)\nconv_1 = BatchNormalization()(conv_1)\npool_1 = MaxPool2D((2,2))(conv_1)\n\n# Stage 2\nconv_2 = resblock(pool_1,32)\npool_2 = MaxPool2D((2,2))(conv_2)\n\n# Stage 3\nconv_3 = resblock(pool_2,64)\npool_3 = MaxPool2D((2,2))(conv_3)\n\n# Stage 4\nconv_4 = resblock(pool_3,128)\npool_4 = MaxPool2D((2,2))(conv_4)\n\n# Stage 5 (bottle neck)\nconv_5 = resblock(pool_4,256)\n\n# Upsample Stage 1\nup_1 = upsample_concat(conv_5,conv_4)\nup_1 = resblock(up_1,128)\n\n# Upsample Stage 2\nup_2 = upsample_concat(up_1,conv_3)\nup_2 = resblock(up_2,64)\n\n# Upsample Stage 3\nup_3 = upsample_concat(up_2,conv_2)\nup_3 = resblock(up_3,32)\n\n# Upsample stage 4\nup_4 = upsample_concat(up_3,conv_1)\nup_4 = resblock(up_4,16)\n\nout = Conv2D(1,(1,1),kernel_initializer='he_normal',padding='same',activation='sigmoid')(up_4)\nseg_model = Model(X_input,out)\nseg_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:08:39.272132Z","iopub.execute_input":"2022-07-07T12:08:39.272505Z","iopub.status.idle":"2022-07-07T12:08:39.744203Z","shell.execute_reply.started":"2022-07-07T12:08:39.272472Z","shell.execute_reply":"2022-07-07T12:08:39.743257Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(seg_model,to_file='seg_model.png')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:09:01.606744Z","iopub.execute_input":"2022-07-07T12:09:01.607174Z","iopub.status.idle":"2022-07-07T12:09:03.237832Z","shell.execute_reply.started":"2022-07-07T12:09:01.607136Z","shell.execute_reply":"2022-07-07T12:09:03.236764Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from keras.losses import binary_crossentropy\n\nepsilon = 1e-5\nsmooth = 1\n\ndef tversky(y_true, y_pred):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\ndef focal_tversky(y_true,y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    pt_1 = tversky(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1-pt_1), gamma)\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true,y_pred)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:09:24.429365Z","iopub.execute_input":"2022-07-07T12:09:24.429922Z","iopub.status.idle":"2022-07-07T12:09:24.441141Z","shell.execute_reply.started":"2022-07-07T12:09:24.429882Z","shell.execute_reply":"2022-07-07T12:09:24.439591Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# compling model and callbacks functions\nadam = tf.keras.optimizers.Adam(learning_rate = 0.05, epsilon = 0.1)\nseg_model.compile(optimizer = adam, \n                  loss = focal_tversky, \n                  metrics = [tversky]\n                 )\n#callbacks\nearlystopping = EarlyStopping(monitor='val_loss',\n                              mode='min', \n                              verbose=1, \n                              patience=20\n                             )\n# save the best model with lower validation loss\ncheckpointer = ModelCheckpoint(filepath=\"ResUNet-segModel-weights.hdf5\", \n                               verbose=1, \n                               save_best_only=True\n                              )\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              mode='min',\n                              verbose=1,\n                              patience=10,\n                              min_delta=0.0001,\n                              factor=0.2\n                             )","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:09:47.263614Z","iopub.execute_input":"2022-07-07T12:09:47.263999Z","iopub.status.idle":"2022-07-07T12:09:47.279702Z","shell.execute_reply.started":"2022-07-07T12:09:47.263964Z","shell.execute_reply":"2022-07-07T12:09:47.278467Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"h = seg_model.fit(train_data,epochs = 100,validation_data = val_data,callbacks=[checkpointer,early_stopping,reduce_lr])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:09:55.482069Z","iopub.execute_input":"2022-07-07T12:09:55.482451Z","iopub.status.idle":"2022-07-07T12:23:30.070105Z","shell.execute_reply.started":"2022-07-07T12:09:55.482401Z","shell.execute_reply":"2022-07-07T12:23:30.069114Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# saving model achitecture in json file\nseg_model_json = seg_model.to_json()\nwith open(\"ResUNet-seg-model.json\", \"w\") as json_file:\n    json_file.write(seg_model_json)\nseg_model.save('seg_model_brain.hdf5')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:23:58.850213Z","iopub.execute_input":"2022-07-07T12:23:58.850753Z","iopub.status.idle":"2022-07-07T12:23:59.810677Z","shell.execute_reply.started":"2022-07-07T12:23:58.850717Z","shell.execute_reply":"2022-07-07T12:23:59.809389Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"h.history.keys()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:24:07.474323Z","iopub.execute_input":"2022-07-07T12:24:07.474820Z","iopub.status.idle":"2022-07-07T12:24:07.482612Z","shell.execute_reply.started":"2022-07-07T12:24:07.474781Z","shell.execute_reply":"2022-07-07T12:24:07.481476Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(h.history['loss']);\nplt.plot(h.history['val_loss']);\nplt.title(\"SEG Model focal tversky Loss\");\nplt.ylabel(\"focal tversky loss\");\nplt.xlabel(\"Epochs\");\nplt.legend(['train', 'val']);\n\nplt.subplot(1,2,2)\nplt.plot(h.history['tversky']);\nplt.plot(h.history['val_tversky']);\nplt.title(\"SEG Model tversky score\");\nplt.ylabel(\"tversky Accuracy\");\nplt.xlabel(\"Epochs\");\nplt.legend(['train', 'val']);\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:24:17.155018Z","iopub.execute_input":"2022-07-07T12:24:17.155375Z","iopub.status.idle":"2022-07-07T12:24:17.491515Z","shell.execute_reply.started":"2022-07-07T12:24:17.155345Z","shell.execute_reply":"2022-07-07T12:24:17.490566Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"test_ids = list(X_test.image_path)\ntest_mask = list(X_test.mask_path)\ntest_data = DataGenerator(test_ids, test_mask)\n_, tv = seg_model.evaluate(test_data)\nprint(\"Segmentation tversky is {:.2f}%\".format(tv*100))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:24:29.247655Z","iopub.execute_input":"2022-07-07T12:24:29.248585Z","iopub.status.idle":"2022-07-07T12:24:30.669143Z","shell.execute_reply.started":"2022-07-07T12:24:29.248550Z","shell.execute_reply":"2022-07-07T12:24:30.668000Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def prediction(test,model,model_seg):\n    mask,image_id,has_mask = [],[],[]\n    \n    for i in test.image_path:\n        img = io.imread(i)\n        img=img*1./255.0\n        img = cv2.resize(img,(256,256))\n        img = np.array(img,dtype=np.float64)\n        img = np.reshape(img,(1,256,256,3))\n        \n        is_defect = model.predict(img)\n        \n        if np.argmax(is_defect) ==0:\n            image_id.append(i)\n            has_mask.append(0)\n            mask.append(\"No Mask :)\")\n            continue\n        \n        X = np.empty((1,256,256,3))\n        img = io.imread(i)\n        img = cv2.resize(img,(256,256))\n        img = np.array(img,dtype=np.float64)\n        img-=img.mean()\n        img/=img.std()\n        X[0,] = img\n        predict = model_seg.predict(X)\n        if predict.round().astype(int).sum()==0:\n            image_id.append(i)\n            has_mask.append(0)\n            mask.append(\"No Mask :)\")\n        else:\n            image_id.append(i)\n            has_mask.append(1)\n            mask.append(predict)\n    return pd.DataFrame({\"image_path\":image_id,'predicted_mask':mask,'has_mask':has_mask})\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:24:46.678622Z","iopub.execute_input":"2022-07-07T12:24:46.678980Z","iopub.status.idle":"2022-07-07T12:24:46.691169Z","shell.execute_reply.started":"2022-07-07T12:24:46.678949Z","shell.execute_reply":"2022-07-07T12:24:46.690208Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"df_pred = prediction(test,model,seg_model)\ndf_pred\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:24:55.178828Z","iopub.execute_input":"2022-07-07T12:24:55.179197Z","iopub.status.idle":"2022-07-07T12:26:12.111769Z","shell.execute_reply.started":"2022-07-07T12:24:55.179165Z","shell.execute_reply":"2022-07-07T12:26:12.110648Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"df_pred = test.merge(df_pred,on='image_path')\ndf_pred.head(10)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:26:43.011885Z","iopub.execute_input":"2022-07-07T12:26:43.012275Z","iopub.status.idle":"2022-07-07T12:26:49.692582Z","shell.execute_reply.started":"2022-07-07T12:26:43.012224Z","shell.execute_reply":"2022-07-07T12:26:49.691495Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"count = 0\nfig,axs = plt.subplots(15,5,figsize=(40,80))\nfor i in range(len(df_pred)):\n    if df_pred.has_mask[i]==1 and count<15:\n        img = io.imread(df_pred.image_path[i])\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        axs[count][0].imshow(img)\n        axs[count][0].title.set_text(\"Brain MRI\")\n        axs[count][0].axis('off')\n        \n        mask = io.imread(df_pred.mask_path[i])\n        axs[count][1].imshow(mask)\n        axs[count][1].title.set_text(\"Original Mask\")\n        axs[count][1].axis('off')\n        \n        pred = np.array(df_pred.predicted_mask[i]).squeeze().round()\n        axs[count][2].imshow(pred)\n        axs[count][2].title.set_text(\"AI Predicted Mask\")\n        axs[count][2].axis('off')\n        \n        img[mask==255] =(255,0,0)\n        axs[count][3].imshow(img)\n        axs[count][3].title.set_text(\"Brain MRI with original Mask (Ground Truth)\")\n        axs[count][3].axis('off')\n        \n        img_ = io.imread(df_pred.image_path[i])\n        img_ = cv2.cvtColor(img_,cv2.COLOR_BGR2RGB)\n        img_[pred==1]= (0,255,150)\n        axs[count][4].imshow(img_)\n        axs[count][4].title.set_text(\"MRI with AI Predicted Mask\")\n        axs[count][4].axis('off')\n        count+=1\n    if(count==15):\n        break\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T12:27:12.584029Z","iopub.execute_input":"2022-07-07T12:27:12.584653Z","iopub.status.idle":"2022-07-07T12:27:19.444630Z","shell.execute_reply.started":"2022-07-07T12:27:12.584615Z","shell.execute_reply":"2022-07-07T12:27:19.443649Z"},"trusted":true},"execution_count":53,"outputs":[]}]}